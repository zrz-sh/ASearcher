{
    "instance_id": "ws_en_062",
    "score": 0.0,
    "precision_by_row": 0.0,
    "recall_by_row": 0.0,
    "f1_by_row": 0.0,
    "precision_by_item": 0.4583333333333333,
    "recall_by_item": 0.1527777777777778,
    "f1_by_item": 0.22916666666666666,
    "msg": "   university_exact_match  foundingyear_exact_match  governingbody_llm_judge  officialwebsiteaddress_llm_judge  2025ukguardianrankings_exact_match  2026qsworldrankings_exact_match\n0                     1.0                       1.0                        0                                 1                                 0.0                              1.0\n1                     1.0                       1.0                        0                                 1                                 0.0                              0.0\n2                     1.0                       1.0                        0                                 1                                 0.0                              0.0\n3                     1.0                       1.0                        0                                 1                                 0.0                              0.0\n4                     1.0                       1.0                        1                                 1                                 1.0                              0.0\n5                     1.0                       1.0                        0                                 1                                 0.0                              1.0"
}