{
    "instance_id": "ws_en_051",
    "score": 0.0,
    "precision_by_row": 0.0,
    "recall_by_row": 0.0,
    "f1_by_row": 0.0,
    "precision_by_item": 0.7142857142857143,
    "recall_by_item": 0.014285714285714285,
    "f1_by_item": 0.028011204481792715,
    "msg": "   highschool_exact_match  states_llm_judge  stemhighschoolsranking_exact_match  nationalrankings_exact_match  staterankings_llm_judge  servedgrades_llm_judge  apcourses_number_near\n0                     1.0                 1                                 1.0                           0.0                        1                       1                    0.0"
}